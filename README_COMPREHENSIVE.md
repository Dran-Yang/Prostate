# å‰åˆ—è…º MRI è‡ªç›‘ç£é¢„è®­ç»ƒå·¥ç¨‹

<div align="center">

**åŸºäº DINOv2 çš„å¤šæ¨¡æ€å‰åˆ—è…º MRI è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![CUDA 12.x](https://img.shields.io/badge/CUDA-12.x-76B900.svg)](https://developer.nvidia.com/cuda-toolkit)

</div>

---

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
2. [ä¸»è¦ç‰¹æ€§](#ä¸»è¦ç‰¹æ€§)
3. [ç¯å¢ƒéœ€æ±‚ä¸å®‰è£…](#ç¯å¢ƒéœ€æ±‚ä¸å®‰è£…)
4. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
5. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
6. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
7. [è®­ç»ƒç›‘æ§](#è®­ç»ƒç›‘æ§)
8. [Resume è®­ç»ƒ](#resume-è®­ç»ƒ)
9. [ä¸‹æ¸¸ä»»åŠ¡](#ä¸‹æ¸¸ä»»åŠ¡)
10. [å¸¸è§é—®é¢˜ FAQ](#å¸¸è§é—®é¢˜-faq)
11. [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
12. [å¼•ç”¨](#å¼•ç”¨)

---

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé¢å‘**å‰åˆ—è…ºå¤šæ¨¡æ€ MRI**çš„è‡ªç›‘ç£é¢„è®­ç»ƒæ¡†æ¶ï¼ŒåŸºäº [DINOv2](https://github.com/facebookresearch/dinov2) å’Œ [mm-dinov2](https://github.com/mahmoodlab/mmdino) æ€æƒ³å¼€å‘ã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡æœªæ ‡æ³¨çš„å‰åˆ—è…º MRI æ•°æ®ä¸Šè¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ï¼Œå¯ä»¥ä¸ºä¸‹æ¸¸çš„**åˆ†å‰²ã€åˆ†çº§ã€åˆ†ç±»**ç­‰ä»»åŠ¡æä¾›å¼ºå¤§çš„é¢„è®­ç»ƒ backboneã€‚

**é€‚ç”¨åœºæ™¯ï¼š**
- å‰åˆ—è…ºç™Œæ£€æµ‹ä¸åˆ†çº§
- å‰åˆ—è…ºåˆ†å‰²
- å¤šå‚æ•° MRIï¼ˆmpMRIï¼‰ç‰¹å¾æå–
- å°‘æ ·æœ¬åŒ»å­¦å½±åƒå­¦ä¹ 

**æ ¸å¿ƒæŠ€æœ¯ï¼š**
- **å¤šæ¨¡æ€è¾“å…¥**ï¼šåŒæ—¶å¤„ç† T2WIã€ADCã€DWI ç­‰å¤šä¸ª MRI åºåˆ—
- **è‡ªç›‘ç£å­¦ä¹ **ï¼šDINO + iBOT è”åˆè®­ç»ƒï¼Œæ— éœ€æ ‡æ³¨æ•°æ®
- **å‰åˆ—è…ºç‰¹å®šä¼˜åŒ–**ï¼šæ”¯æŒåŸºäº ROI çš„è£å‰ªï¼Œæé«˜ç—…ç¶åŒºåŸŸå­¦ä¹ æ•ˆç‡
- **ç¨³å®šè®­ç»ƒ**ï¼šfp32 ç­–ç•¥ + xFormers åŠ é€Ÿï¼Œé€‚åˆåŒ»å­¦å½±åƒçš„æ•°å€¼ç¨³å®šæ€§è¦æ±‚

---

## ä¸»è¦ç‰¹æ€§

### âœ¨ æ ¸å¿ƒåŠŸèƒ½

- ğŸ¯ **å¤šæ¨¡æ€ MRI æ”¯æŒ**ï¼šçµæ´»é…ç½® T2WIã€ADCã€DWI ç­‰åºåˆ—ç»„åˆ
- ğŸ¥ **åŒ»å­¦å½±åƒä¼˜åŒ–**ï¼šé’ˆå¯¹å‰åˆ—è…º MRI çš„æ•°æ®å¢å¼ºç­–ç•¥
- ğŸš€ **é«˜æ•ˆè®­ç»ƒ**ï¼šxFormers åŠ é€Ÿ + å¯é€‰çš„ FSDP å¤šå¡æ”¯æŒ
- ğŸ“Š **ROI å¼•å¯¼**ï¼šå¯é€‰çš„åŸºäºå‰åˆ—è…ºåˆ†å‰² mask çš„å‰æ™¯è£å‰ª
- ğŸ’¾ **çµæ´»çš„æ£€æŸ¥ç‚¹**ï¼šæ”¯æŒå•å¡å’Œå¤šå¡çš„æ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤
- ğŸ”§ **å¯æ‰©å±•æ¶æ„**ï¼šæ˜“äºæ·»åŠ æ–°çš„ MRI åºåˆ—æˆ–ä¸‹æ¸¸ä»»åŠ¡

### ğŸ› ï¸ æŠ€æœ¯äº®ç‚¹

- **fp32 è®­ç»ƒç­–ç•¥**ï¼šç¡®ä¿åŒ»å­¦å½±åƒæ•°å€¼ç¨³å®šæ€§ï¼Œé¿å…ç²¾åº¦æŸå¤±
- **æ™ºèƒ½ DWI é€‰æ‹©**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€é«˜ b å€¼çš„ DWI åºåˆ—
- **é²æ£’çš„æ•°æ®åŠ è½½**ï¼šå¤„ç†ç¼ºå¤±æ¨¡æ€ã€ä¸åŒåˆ‡ç‰‡æ•°ç­‰è¾¹ç•Œæƒ…å†µ
- **éšæœºè½´é€‰æ‹©**ï¼šè®­ç»ƒæ—¶éšæœºé€‰æ‹©è½´ä½/å† çŠ¶ä½/çŸ¢çŠ¶ä½ï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–æ€§
- **ç™¾åˆ†æ¯”æ ‡æ³¨**ï¼šæ”¯æŒåŠç›‘ç£å­¦ä¹ ï¼Œå¯é…ç½®ä½¿ç”¨éƒ¨åˆ†æ ‡æ³¨æ•°æ®

---

## ç¯å¢ƒéœ€æ±‚ä¸å®‰è£…

### 1. ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šLinuxï¼ˆæ¨è Ubuntu 20.04/22.04ï¼‰æˆ– WSL2
- **GPU**ï¼šNVIDIA GPU with CUDA 12.xï¼ˆæ¨è RTX 3090/4090 æˆ–æ›´é«˜ï¼‰
- **æ˜¾å­˜**ï¼šè‡³å°‘ 16GBï¼ˆæ¨è 24GB+ï¼‰
- **å†…å­˜**ï¼š32GB+
- **ç£ç›˜**ï¼šSSDï¼ˆNIfTI æ–‡ä»¶ I/O å¯†é›†ï¼‰

### 2. Python ç¯å¢ƒ

æ¨èä½¿ç”¨ **Python 3.10** æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚

#### ä½¿ç”¨ Conda åˆ›å»ºç¯å¢ƒ

```bash
# åˆ›å»ºæ–°ç¯å¢ƒ
conda create -n prostate-ssl python=3.10 -y
conda activate prostate-ssl

# å®‰è£… PyTorchï¼ˆCUDA 12.1 ç‰ˆæœ¬ï¼‰
conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia

# éªŒè¯ PyTorch å®‰è£…
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

#### æˆ–ä½¿ç”¨ virtualenv

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv prostate-ssl-env
source prostate-ssl-env/bin/activate

# å®‰è£… PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### 3. å®‰è£…ä¾èµ–åŒ…

åˆ›å»º `requirements.txt` æ–‡ä»¶ï¼ˆå¦‚æœé¡¹ç›®ä¸­è¿˜æ²¡æœ‰ï¼‰ï¼š

```bash
cat > requirements.txt << 'EOF'
# æ ¸å¿ƒä¾èµ–
torch>=2.0.0
torchvision>=0.15.0
omegaconf>=2.3.0
timm>=0.9.0

# åŒ»å­¦å½±åƒå¤„ç†
monai>=1.2.0
nibabel>=5.0.0
SimpleITK>=2.2.0

# åˆ†å¸ƒå¼è®­ç»ƒ
fvcore>=0.1.5

# xFormersï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰
xformers>=0.0.20

# æ•°æ®å¤„ç†
pandas>=2.0.0
numpy>=1.24.0
scipy>=1.10.0

# å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
tensorboard>=2.13.0
matplotlib>=3.7.0

# å·¥å…·
tqdm>=4.65.0
pyyaml>=6.0
EOF

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 4. å®‰è£… xFormersï¼ˆé‡è¦ï¼‰

xFormers æä¾›äº†é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶å®ç°ï¼Œèƒ½æ˜¾è‘—åŠ é€Ÿè®­ç»ƒã€‚

```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨ pipï¼ˆæ¨èï¼‰
pip install xformers

# æ–¹æ³• 2ï¼šä»æºç ç¼–è¯‘ï¼ˆå¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼‰
pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers

# éªŒè¯å®‰è£…
python -c "import xformers; print(f'xFormers version: {xformers.__version__}')"
```

**å¦‚æœæ— æ³•å®‰è£… xFormersï¼š**
- å¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡ `XFORMERS_DISABLED=1` ç»§ç»­è¿è¡Œï¼ˆæ€§èƒ½ä¼šä¸‹é™ï¼‰
- æˆ–è€…ä½¿ç”¨çº¯ PyTorch å®ç°ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼Œè§ FAQï¼‰

### 5. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/Dran-Yang/Prostate.git
cd Prostate
```

### 6. éªŒè¯å®‰è£…

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯ç¯å¢ƒæ˜¯å¦æ­£ç¡®ï¼š

```bash
python -c "
import torch
import monai
import nibabel as nib
print('âœ“ PyTorch:', torch.__version__)
print('âœ“ CUDA available:', torch.cuda.is_available())
print('âœ“ MONAI:', monai.__version__)
print('âœ“ nibabel:', nib.__version__)
try:
    import xformers
    print('âœ“ xFormers:', xformers.__version__)
except ImportError:
    print('âœ— xFormers not installed')
"
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ“ PyTorch: 2.x.x
âœ“ CUDA available: True
âœ“ MONAI: 1.x.x
âœ“ nibabel: 5.x.x
âœ“ xFormers: 0.x.x
```

---

## æ•°æ®å‡†å¤‡

### 1. æ•°æ®ç»„ç»‡ç»“æ„

é¡¹ç›®æœŸæœ›æ¯ä¸ªç—…ä¾‹å­˜æ”¾åœ¨ç‹¬ç«‹çš„æ–‡ä»¶å¤¹ä¸­ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«å¤šä¸ª MRI åºåˆ—å’Œå¯é€‰çš„åˆ†å‰² maskã€‚

#### æ ‡å‡†ç›®å½•ç»“æ„

```
/path/to/prostate_dataset/
â”œâ”€â”€ patient_001/
â”‚   â”œâ”€â”€ ax_t2wi.nii.gz         # T2 åŠ æƒåƒï¼ˆè½´ä½ï¼‰
â”‚   â”œâ”€â”€ ax_adc.nii.gz          # è¡¨è§‚æ‰©æ•£ç³»æ•°ï¼ˆADCï¼‰
â”‚   â”œâ”€â”€ ax_dwi_b1000.nii.gz    # æ‰©æ•£åŠ æƒåƒï¼ˆDWIï¼Œb=1000ï¼‰
â”‚   â”œâ”€â”€ ax_dwi_b2000.nii.gz    # DWIï¼ˆb=2000ï¼Œå¯é€‰ï¼‰
â”‚   â””â”€â”€ roi_Prostate.nii.gz    # å‰åˆ—è…ºåˆ†å‰² maskï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ patient_002/
â”‚   â”œâ”€â”€ ax_t2wi.nii
â”‚   â”œâ”€â”€ ax_adc.nii
â”‚   â”œâ”€â”€ ax_dwi_1000.nii
â”‚   â””â”€â”€ roi_Prostate.nii
â””â”€â”€ patient_003/
    â””â”€â”€ ...
```

#### å‘½åè§„èŒƒ

**å¿…éœ€çš„ MRI åºåˆ—**ï¼ˆé»˜è®¤é…ç½®ï¼‰ï¼š
- `ax_t2wi.nii` æˆ– `ax_t2wi.nii.gz`ï¼šT2 åŠ æƒåƒ
- `ax_adc.nii` æˆ– `ax_adc.nii.gz`ï¼šè¡¨è§‚æ‰©æ•£ç³»æ•°
- `ax_dwi_*.nii` æˆ– `ax_dwi_*.nii.gz`ï¼šæ‰©æ•£åŠ æƒåƒï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€é«˜ b å€¼ï¼‰

**å¯é€‰æ–‡ä»¶**ï¼š
- `roi_Prostate.nii` æˆ– `roi_Prostate.nii.gz`ï¼šå‰åˆ—è…ºåˆ†å‰² mask
  - å¦‚æœè®¾ç½® `crop_from_tumor_foreground: True`ï¼Œä¼šåŸºäºæ­¤ mask è¿›è¡Œå‰æ™¯è£å‰ª
  - å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¼šä½¿ç”¨æ•´ä¸ªå›¾åƒçš„ä¸­å¿ƒåŒºåŸŸ

**DWI å‘½åçµæ´»æ€§**ï¼š
ä»£ç ä¼šè‡ªåŠ¨æœç´¢ `ax_dwi*.nii*` æ–‡ä»¶å¹¶é€‰æ‹© b å€¼æœ€é«˜çš„ã€‚æ”¯æŒä»¥ä¸‹å‘½åæ ¼å¼ï¼š
- `ax_dwi_b1000.nii.gz` âœ“
- `ax_dwi_1000.nii` âœ“
- `dwi_b2000.nii.gz` âœ“
- `dwi_2000.nii` âœ“

### 2. DICOM è½¬ NIfTI

å¦‚æœä½ çš„åŸå§‹æ•°æ®æ˜¯ DICOM æ ¼å¼ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸º NIfTIã€‚

#### æ–¹æ³• 1ï¼šä½¿ç”¨ dcm2niixï¼ˆæ¨èï¼‰

```bash
# å®‰è£… dcm2niix
sudo apt-get install dcm2niix  # Ubuntu
# æˆ–
conda install -c conda-forge dcm2niix

# è½¬æ¢å•ä¸ªç—…ä¾‹
dcm2niix -o /output/patient_001 -f ax_t2wi /input/patient_001/T2_DICOM_folder

# æ‰¹é‡è½¬æ¢è„šæœ¬ç¤ºä¾‹
for patient_dir in /input/*/; do
    patient_id=$(basename "$patient_dir")
    dcm2niix -o "/output/$patient_id" -f ax_t2wi "$patient_dir/T2_DICOM/"
    dcm2niix -o "/output/$patient_id" -f ax_adc "$patient_dir/ADC_DICOM/"
    dcm2niix -o "/output/$patient_id" -f ax_dwi_b1000 "$patient_dir/DWI_b1000_DICOM/"
done
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨ SimpleITK

```python
import SimpleITK as sitk
import os

def convert_dicom_series_to_nifti(dicom_dir, output_path):
    """è¯»å– DICOM åºåˆ—å¹¶ä¿å­˜ä¸º NIfTI"""
    reader = sitk.ImageSeriesReader()
    dicom_names = reader.GetGDCMSeriesFileNames(dicom_dir)
    reader.SetFileNames(dicom_names)
    image = reader.Execute()
    sitk.WriteImage(image, output_path)

# ä½¿ç”¨ç¤ºä¾‹
convert_dicom_series_to_nifti(
    "/input/patient_001/T2_DICOM/",
    "/output/patient_001/ax_t2wi.nii.gz"
)
```

#### æ–¹æ³• 3ï¼šä½¿ç”¨ MONAI

```python
from monai.transforms import LoadImage
from monai.data import write_nifti

loader = LoadImage(image_only=False)
image, meta = loader("/input/patient_001/T2_DICOM/")
write_nifti(
    image,
    "/output/patient_001/ax_t2wi.nii.gz",
    affine=meta["affine"],
)
```

### 3. æ•°æ®é›†åˆ†å‰²

åˆ›å»ºè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†çš„ CSV æ–‡ä»¶ã€‚

#### åˆ›å»º split CSV

```bash
# åˆ›å»º split ç›®å½•
mkdir -p split

# ç”Ÿæˆè®­ç»ƒé›† CSVï¼ˆç¤ºä¾‹ï¼‰
cat > split/train.csv << 'EOF'
patient_id
patient_001
patient_002
patient_003
patient_004
patient_005
EOF

# ç”ŸæˆéªŒè¯é›† CSV
cat > split/val.csv << 'EOF'
patient_id
patient_006
patient_007
EOF

# ç”Ÿæˆæµ‹è¯•é›† CSV
cat > split/test.csv << 'EOF'
patient_id
patient_008
patient_009
EOF
```

**CSV æ ¼å¼è¯´æ˜ï¼š**
- ç¬¬ä¸€è¡Œæ˜¯åˆ—åï¼Œæ”¯æŒå¤šç§å‘½åï¼š`patient_id`, `case_id`, `id`, `ID`, `subject`, `name`
- æ¯è¡Œä¸€ä¸ªç—…ä¾‹ IDï¼Œéœ€è¦ä¸æ•°æ®ç›®å½•ä¸­çš„æ–‡ä»¶å¤¹åå®Œå…¨åŒ¹é…
- æ–‡ä»¶å¿…é¡»æ˜¯ UTF-8 ç¼–ç 

#### è‡ªåŠ¨ç”Ÿæˆ split è„šæœ¬

```python
import os
import pandas as pd
from sklearn.model_selection import train_test_split

# æ‰«ææ•°æ®ç›®å½•
data_root = "/path/to/prostate_dataset"
patient_ids = sorted([d for d in os.listdir(data_root) 
                      if os.path.isdir(os.path.join(data_root, d))])

# åˆ†å‰²æ•°æ®é›†ï¼ˆ70% è®­ç»ƒï¼Œ15% éªŒè¯ï¼Œ15% æµ‹è¯•ï¼‰
train_ids, temp_ids = train_test_split(patient_ids, test_size=0.3, random_state=42)
val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)

# ä¿å­˜ CSV
os.makedirs("split", exist_ok=True)
pd.DataFrame({"patient_id": train_ids}).to_csv("split/train.csv", index=False)
pd.DataFrame({"patient_id": val_ids}).to_csv("split/val.csv", index=False)
pd.DataFrame({"patient_id": test_ids}).to_csv("split/test.csv", index=False)

print(f"âœ“ è®­ç»ƒé›†: {len(train_ids)} ç—…ä¾‹")
print(f"âœ“ éªŒè¯é›†: {len(val_ids)} ç—…ä¾‹")
print(f"âœ“ æµ‹è¯•é›†: {len(test_ids)} ç—…ä¾‹")
```

### 4. æ•°æ®è´¨é‡æ£€æŸ¥

åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œå»ºè®®è¿è¡Œä»¥ä¸‹è„šæœ¬æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼š

```python
import os
import nibabel as nib
from pathlib import Path

def check_dataset(data_root, split_csv):
    """æ£€æŸ¥æ•°æ®é›†å®Œæ•´æ€§"""
    import pandas as pd
    
    df = pd.read_csv(split_csv)
    patient_ids = df.iloc[:, 0].tolist()
    
    issues = []
    required_files = ["ax_t2wi", "ax_adc"]
    
    for pid in patient_ids:
        patient_dir = Path(data_root) / pid
        
        if not patient_dir.exists():
            issues.append(f"âŒ {pid}: ç›®å½•ä¸å­˜åœ¨")
            continue
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        for seq in required_files:
            found = list(patient_dir.glob(f"{seq}.nii*"))
            if not found:
                issues.append(f"âš ï¸ {pid}: ç¼ºå°‘ {seq}")
        
        # æ£€æŸ¥ DWI
        dwi_files = list(patient_dir.glob("ax_dwi*.nii*")) + list(patient_dir.glob("dwi*.nii*"))
        if not dwi_files:
            issues.append(f"âš ï¸ {pid}: ç¼ºå°‘ DWI åºåˆ—")
        
        # æ£€æŸ¥ ROIï¼ˆå¯é€‰ï¼‰
        roi_files = list(patient_dir.glob("roi_Prostate.nii*"))
        if not roi_files:
            issues.append(f"â„¹ï¸ {pid}: æ²¡æœ‰ ROI maskï¼ˆå¯é€‰ï¼‰")
    
    if issues:
        print("\n".join(issues))
    else:
        print(f"âœ“ æ‰€æœ‰ {len(patient_ids)} ä¸ªç—…ä¾‹æ£€æŸ¥é€šè¿‡ï¼")
    
    return len(issues) == 0

# ä½¿ç”¨ç¤ºä¾‹
check_dataset("/path/to/prostate_dataset", "split/train.csv")
```

---

## å¿«é€Ÿå¼€å§‹

### 1. ä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `dinov2/configs/train/prostate_vitb14_mm-dino.yaml`ï¼š

```yaml
train:
  # ä¿®æ”¹è¿™é‡Œï¼šæŒ‡å‘ä½ çš„æ•°æ®æ ¹ç›®å½•
  dataset_path: ProstateSSL:split=TRAIN:root=/path/to/prostate_dataset:split_csv=split/train.csv:mri_sequences=ax_t2wi,ax_adc,ax_dwi:random_axes=True:random_slices=True
  
  batch_size_per_gpu: 8  # æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼ˆ4-12ï¼‰
  num_workers: 4
  OFFICIAL_EPOCH_LENGTH: 50  # ceil(è®­ç»ƒé›†ç—…ä¾‹æ•° / batch_size_per_gpu)
  
  # ä¿®æ”¹è¿™é‡Œï¼šè¾“å‡ºç›®å½•
  output_dir: ./output/prostate_ssl_run1

optim:
  base_lr: 3.5e-4  # é€‚åˆ batch_size=8 çš„å­¦ä¹ ç‡
  epochs: 300
  warmup_epochs: 30
```

**å‚æ•°è¯´æ˜ï¼š**
- `root`ï¼šæ•°æ®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
- `split_csv`ï¼šè®­ç»ƒé›† CSV æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
- `mri_sequences`ï¼šä½¿ç”¨çš„ MRI åºåˆ—ï¼Œé€—å·åˆ†éš”
- `random_axes`ï¼šè®­ç»ƒæ—¶éšæœºé€‰æ‹©è½´ä½/å† çŠ¶ä½/çŸ¢çŠ¶ä½ï¼ˆå»ºè®® `True`ï¼‰
- `random_slices`ï¼šéšæœºé€‰æ‹©åˆ‡ç‰‡ï¼ˆå»ºè®® `True`ï¼‰
- `OFFICIAL_EPOCH_LENGTH`ï¼šæ¯ä¸ª epoch çš„è¿­ä»£æ¬¡æ•°ï¼Œå»ºè®®è®¾ä¸º `ceil(ç—…ä¾‹æ•° / batch_size)`

### 2. å•å¡è®­ç»ƒï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
cd Prostate/dinov2

# æ–¹æ³• 1ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶
python -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output

# æ–¹æ³• 2ï¼šå‘½ä»¤è¡Œè¦†ç›–é…ç½®
python -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output \
  train.batch_size_per_gpu=8 \
  optim.base_lr=3.5e-4 \
  optim.epochs=300
```

### 3. å¤šå¡è®­ç»ƒ

```bash
cd Prostate/dinov2

# ä½¿ç”¨ torchrunï¼ˆæ¨èï¼‰
torchrun --nproc_per_node=4 -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output

# æˆ–ä½¿ç”¨ python -m torch.distributed.launchï¼ˆæ—§ç‰ˆï¼‰
python -m torch.distributed.launch \
  --nproc_per_node=4 \
  --use_env \
  -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output
```

**æ³¨æ„ï¼š**
- `--nproc_per_node`ï¼šGPU æ•°é‡
- å¤šå¡è®­ç»ƒä¼šè‡ªåŠ¨ä½¿ç”¨ FSDPï¼ˆFully Sharded Data Parallelï¼‰
- å­¦ä¹ ç‡ä¼šæ ¹æ®æ€» batch size è‡ªåŠ¨è°ƒæ•´ï¼ˆä½¿ç”¨ sqrt scalingï¼‰

### 4. è¿è¡Œ Smoke Testï¼ˆæ¨èé¦–æ¬¡è¿è¡Œï¼‰

åœ¨æ­£å¼è®­ç»ƒå‰ï¼Œå»ºè®®å…ˆç”¨å°‘é‡æ•°æ®éªŒè¯æµç¨‹ï¼š

```bash
cd Prostate/dinov2

# è®¾ç½®æµ‹è¯•æ•°æ®è·¯å¾„ï¼ˆ2-4 ä¸ªç—…ä¾‹å³å¯ï¼‰
export PROSTATE_DATA_ROOT=/path/to/small_subset

# è¿è¡Œ smoke testï¼ˆ5 ä¸ªè¿­ä»£ï¼‰
python tests/test_prostate_ssl_training.py
```

é¢„æœŸè¾“å‡ºï¼š
```
[step 0] loss=X.XXXX
[step 1] loss=X.XXXX
[step 2] loss=X.XXXX
[step 3] loss=X.XXXX
[step 4] loss=X.XXXX
Smoke test completed without runtime errors.
```

å¦‚æœå‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š
- æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®
- æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚
- CUDA æ˜¯å¦å¯ç”¨

---

## é…ç½®è¯´æ˜

### å…³é”®é…ç½®å‚æ•°è¯¦è§£

#### 1. æ•°æ®ç›¸å…³ (`train` éƒ¨åˆ†)

```yaml
train:
  dataset_path: "ProstateSSL:split=TRAIN:root=/data:split_csv=split/train.csv:mri_sequences=ax_t2wi,ax_adc,ax_dwi:random_axes=True:random_slices=True"
  batch_size_per_gpu: 8
  num_workers: 4
  OFFICIAL_EPOCH_LENGTH: 50
  img_size: 224
  percentage_labels: 1.0  # ä½¿ç”¨å¤šå°‘æ¯”ä¾‹çš„æ ‡æ³¨æ•°æ®ï¼ˆ0-1ï¼‰
```

**`dataset_path` æ ¼å¼ï¼š**
- æ ¼å¼ï¼š`DatasetName:key1=value1:key2=value2:...`
- å¿…éœ€å­—æ®µï¼š
  - `split`ï¼šTRAIN / VAL / TEST
  - `root`ï¼šæ•°æ®æ ¹ç›®å½•
- å¯é€‰å­—æ®µï¼š
  - `split_csv`ï¼šCSV æ–‡ä»¶è·¯å¾„
  - `mri_sequences`ï¼šä½¿ç”¨çš„åºåˆ—ï¼ˆé»˜è®¤ï¼š`ax_t2wi,ax_adc,ax_dwi`ï¼‰
  - `random_axes`ï¼šéšæœºé€‰æ‹©åˆ‡ç‰‡è½´ï¼ˆé»˜è®¤ï¼šFalseï¼‰
  - `random_slices`ï¼šéšæœºé€‰æ‹©åˆ‡ç‰‡ï¼ˆé»˜è®¤ï¼šFalseï¼‰

**`percentage_labels` è¯´æ˜ï¼š**
- æ§åˆ¶ä½¿ç”¨å¤šå°‘æ¯”ä¾‹çš„åˆ†å‰² mask
- `1.0`ï¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ maskï¼ˆå…¨ç›‘ç£ï¼‰
- `0.5`ï¼šéšæœºé€‰æ‹© 50% çš„ç—…ä¾‹ä½¿ç”¨ mask
- `0.0`ï¼šå®Œå…¨ä¸ä½¿ç”¨ maskï¼ˆçº¯è‡ªç›‘ç£ï¼‰

#### 2. æ¨¡å‹ç›¸å…³ (`student` éƒ¨åˆ†)

```yaml
student:
  arch: glioma_vit_base  # æ¨¡å‹æ¶æ„
  patch_size: 14         # patch å¤§å°
  drop_path_rate: 0.1    # DropPath æ¯”ä¾‹
  use_mri_seq_embed: True      # ä½¿ç”¨åºåˆ—åµŒå…¥
  img_wise_pos_embed: True     # ä½¿ç”¨å›¾åƒçº§ä½ç½®ç¼–ç 
  pretrained_weights: ""       # é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
```

**æ¨¡å‹æ¶æ„é€‰é¡¹ï¼š**
- `glioma_vit_small`ï¼šå°æ¨¡å‹ï¼Œ~22M å‚æ•°
- `glioma_vit_base`ï¼šåŸºç¡€æ¨¡å‹ï¼Œ~86M å‚æ•°ï¼ˆæ¨èï¼‰
- `glioma_vit_large`ï¼šå¤§æ¨¡å‹ï¼Œ~304M å‚æ•°
- `glioma_vit_giant2`ï¼šè¶…å¤§æ¨¡å‹ï¼Œ~1.1B å‚æ•°

**MRI ç‰¹å®šå‚æ•°ï¼š**
- `use_mri_seq_embed=True`ï¼šä¸ºæ¯ä¸ª MRI åºåˆ—å­¦ä¹ ç‹¬ç«‹çš„åµŒå…¥ï¼ˆæ¨èå¼€å¯ï¼‰
- `img_wise_pos_embed=True`ï¼šæ¯ä¸ªåºåˆ—ç‹¬ç«‹çš„ä½ç½®ç¼–ç ï¼ˆæ¨èå¼€å¯ï¼‰

#### 3. ä¼˜åŒ–å™¨ç›¸å…³ (`optim` éƒ¨åˆ†)

```yaml
optim:
  base_lr: 3.5e-4              # åŸºç¡€å­¦ä¹ ç‡
  epochs: 300                  # æ€»è®­ç»ƒè½®æ•°
  warmup_epochs: 30            # warmup è½®æ•°
  weight_decay: 0.04           # æƒé‡è¡°å‡
  weight_decay_end: 0.4        # æœ€ç»ˆæƒé‡è¡°å‡
  clip_grad: 3.0               # æ¢¯åº¦è£å‰ª
  freeze_backbone_epochs: 0    # å†»ç»“ backbone çš„è½®æ•°
  
  # é«˜çº§å‚æ•°
  scaling_rule: sqrt_wrt_1024  # å­¦ä¹ ç‡ç¼©æ”¾è§„åˆ™
  patch_embed_lr_mult: 0.2     # patch embedding å­¦ä¹ ç‡å€æ•°
  layerwise_decay: 0.9         # å±‚çº§å­¦ä¹ ç‡è¡°å‡
```

**å­¦ä¹ ç‡è®¾ç½®å»ºè®®ï¼š**
- å•å¡ï¼Œbatch_size=4: `base_lr: 2.5e-4`
- å•å¡ï¼Œbatch_size=8: `base_lr: 3.5e-4`
- åŒå¡ï¼Œbatch_size=8: `base_lr: 5e-4`
- å››å¡ï¼Œbatch_size=8: `base_lr: 7e-4`

#### 4. æ•°æ®å¢å¼º (`crops` éƒ¨åˆ†)

```yaml
crops:
  global_crops_size: 224        # å…¨å±€è£å‰ªå°ºå¯¸
  local_crops_size: 112         # å±€éƒ¨è£å‰ªå°ºå¯¸
  global_crops_scale: [0.5, 1.0]    # å…¨å±€è£å‰ªç¼©æ”¾èŒƒå›´
  local_crops_scale: [0.2, 0.5]     # å±€éƒ¨è£å‰ªç¼©æ”¾èŒƒå›´
  crop_from_tumor_foreground: True  # åŸºäºå‰åˆ—è…º ROI è£å‰ª
  intensity_aug: rc                 # å¼ºåº¦å¢å¼ºç±»å‹
  max_blur_radius: 1                # æœ€å¤§æ¨¡ç³ŠåŠå¾„
  gamma_range: [0.75, 1.5]          # Gamma å˜æ¢èŒƒå›´
```

**`intensity_aug` é€‰é¡¹ï¼š**
- `rc`ï¼šRandConvï¼ˆéšæœºå·ç§¯ï¼Œé€‚åˆåŒ»å­¦å½±åƒï¼‰
- `color_jittering`ï¼šé¢œè‰²æŠ–åŠ¨ï¼ˆä¸æ¨èç”¨äºç°åº¦åŒ»å­¦å½±åƒï¼‰
- `none`ï¼šä¸ä½¿ç”¨å¼ºåº¦å¢å¼º

**`crop_from_tumor_foreground` è¯´æ˜ï¼š**
- `True`ï¼šè£å‰ªæ—¶ä¼˜å…ˆåŒ…å«å‰åˆ—è…ºåŒºåŸŸï¼ˆéœ€è¦ ROI maskï¼‰
- `False`ï¼šéšæœºè£å‰ªæ•´ä¸ªå›¾åƒ

#### 5. æŸå¤±å‡½æ•° (`dino`, `ibot` éƒ¨åˆ†)

```yaml
dino:
  head_n_prototypes: 4096      # DINO åŸå‹æ•°é‡
  head_bottleneck_dim: 256     # ç“¶é¢ˆå±‚ç»´åº¦
  koleo_loss_weight: 0.1       # KoLeo æ­£åˆ™åŒ–æƒé‡

ibot:
  head_n_prototypes: 4096      # iBOT åŸå‹æ•°é‡
  mask_per_channel: True       # æ¯ä¸ªé€šé“ç‹¬ç«‹ maskï¼ˆé‡è¦ï¼‰
  mask_ratio_min_max: [0.1, 0.5]  # mask æ¯”ä¾‹èŒƒå›´
```

**`mask_per_channel` è¯´æ˜ï¼š**
- `True`ï¼šæ¯ä¸ª MRI åºåˆ—ç‹¬ç«‹ç”Ÿæˆ maskï¼ˆæ¨èï¼‰
- `False`ï¼šæ‰€æœ‰åºåˆ—å…±äº«åŒä¸€ä¸ª mask

#### 6. è¯„ä¼°ç›¸å…³ (`evaluation` éƒ¨åˆ†)

```yaml
evaluation:
  eval_period_iterations: 1000  # æ¯éš”å¤šå°‘æ¬¡è¿­ä»£è¯„ä¼°ä¸€æ¬¡ï¼ˆ0=ç¦ç”¨ï¼‰
  train_dataset_path: ""        # è®­ç»ƒé›†è·¯å¾„ï¼ˆç”¨äºè¯„ä¼°ï¼‰
  val_dataset_path: ""          # éªŒè¯é›†è·¯å¾„
  metric_types: ["mcc"]         # è¯„ä¼°æŒ‡æ ‡
```

**æ³¨æ„ï¼š**
- å¦‚æœè®¾ç½® `eval_period_iterations > 0`ï¼Œéœ€è¦æä¾›æ ‡æ³¨çš„éªŒè¯é›†
- è‡ªç›‘ç£é¢„è®­ç»ƒé€šå¸¸è®¾ç½®ä¸º `0`ï¼ˆç¦ç”¨è¯„ä¼°ï¼‰

---

## è®­ç»ƒç›‘æ§

### 1. æ—¥å¿—è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šåœ¨ç»ˆç«¯è¾“å‡ºæ—¥å¿—ï¼š

```
[2024-12-07 10:00:00] Training  [    0/15000]  eta: 2:30:00  lr: 0.000350  wd: 0.040  ...
[2024-12-07 10:00:10] Training  [   10/15000]  eta: 2:29:50  lr: 0.000352  wd: 0.040  ...
```

**å…³é”®æŒ‡æ ‡ï¼š**
- `eta`ï¼šé¢„è®¡å‰©ä½™æ—¶é—´
- `lr`ï¼šå½“å‰å­¦ä¹ ç‡
- `wd`ï¼šå½“å‰æƒé‡è¡°å‡
- `total_loss`ï¼šæ€»æŸå¤±
- `dino_local_crops_loss`ï¼šDINO å±€éƒ¨è£å‰ªæŸå¤±
- `ibot_loss`ï¼šiBOT æŸå¤±

### 2. TensorBoard å¯è§†åŒ–

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir=/path/to/output --port=6006

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
# http://localhost:6006
```

å¯ä»¥æŸ¥çœ‹ï¼š
- æŸå¤±æ›²çº¿
- å­¦ä¹ ç‡å˜åŒ–
- æƒé‡è¡°å‡å˜åŒ–
- æ¢¯åº¦åˆ†å¸ƒ

### 3. è®­ç»ƒæŒ‡æ ‡æ–‡ä»¶

æ‰€æœ‰æŒ‡æ ‡ä¼šä¿å­˜åˆ° `output_dir/training_metrics.json`ï¼š

```json
{
  "0": {
    "lr": 0.00035,
    "wd": 0.04,
    "total_loss": 5.234,
    ...
  },
  "10": {
    "lr": 0.000352,
    "wd": 0.04,
    "total_loss": 5.123,
    ...
  }
}
```

### 4. æ£€æŸ¥ç‚¹ä¿å­˜

æ£€æŸ¥ç‚¹ä¿å­˜åœ¨ `output_dir/` ä¸‹ï¼š

```
output_dir/
â”œâ”€â”€ config.yaml                    # è®­ç»ƒé…ç½®
â”œâ”€â”€ training_metrics.json          # è®­ç»ƒæŒ‡æ ‡
â”œâ”€â”€ model_0001000.rank_0.pth      # æ£€æŸ¥ç‚¹ï¼ˆiteration 1000ï¼‰
â”œâ”€â”€ model_0002000.rank_0.pth
â””â”€â”€ last_checkpoint.rank_0         # æœ€æ–°æ£€æŸ¥ç‚¹è·¯å¾„
```

**æ£€æŸ¥ç‚¹ä¿å­˜é¢‘ç‡ï¼š**
- ç”± `saveckp_freq` æ§åˆ¶ï¼ˆå•ä½ï¼šepochï¼‰
- é»˜è®¤æ¯ 10 ä¸ª epoch ä¿å­˜ä¸€æ¬¡
- æœ€å¤šä¿ç•™ 3 ä¸ªæ£€æŸ¥ç‚¹ï¼ˆ`max_to_keep=3`ï¼‰

### 5. ç›‘æ§è®­ç»ƒçŠ¶æ€

#### æ£€æŸ¥ GPU ä½¿ç”¨æƒ…å†µ

```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨ gpustat
pip install gpustat
gpustat -i 1
```

#### æ£€æŸ¥å†…å­˜ä½¿ç”¨

```bash
# æŸ¥çœ‹è¿›ç¨‹å†…å­˜
ps aux | grep python | grep train

# æŸ¥çœ‹ç³»ç»Ÿå†…å­˜
free -h
```

#### å°¾éšæ—¥å¿—æ–‡ä»¶

```bash
tail -f /path/to/output/log.txt
```

---

## Resume è®­ç»ƒ

### 1. è‡ªåŠ¨ Resume

è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æ¢å¤æœ€æ–°çš„æ£€æŸ¥ç‚¹ï¼š

```bash
# ç›´æ¥è¿è¡Œï¼Œä¼šè‡ªåŠ¨ resume
python -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output
```

### 2. ç¦ç”¨ Resume

å¦‚æœæƒ³ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆå¿½ç•¥å·²æœ‰æ£€æŸ¥ç‚¹ï¼‰ï¼š

```bash
python -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output \
  --no-resume
```

### 3. ä»æŒ‡å®šæ£€æŸ¥ç‚¹æ¢å¤

```bash
python -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output \
  MODEL.WEIGHTS=/path/to/model_0001000.rank_0.pth
```

### 4. ä¿®æ”¹è®­ç»ƒå‚æ•°å Resume

å¦‚æœéœ€è¦æ”¹å˜å­¦ä¹ ç‡æˆ–å…¶ä»–å‚æ•°åç»§ç»­è®­ç»ƒï¼š

```bash
python -m train.train \
  --config-file configs/train/prostate_vitb14_mm-dino.yaml \
  --output-dir /path/to/output \
  optim.base_lr=1e-4 \
  optim.epochs=400  # å»¶é•¿è®­ç»ƒ
```

**æ³¨æ„ï¼š**
- ä¼˜åŒ–å™¨çŠ¶æ€ä¼šæ¢å¤ï¼Œå­¦ä¹ ç‡ä¼šä»æ¢å¤çš„ iteration å¤„å¼€å§‹è°ƒåº¦
- å¦‚æœå¤§å¹…ä¿®æ”¹è®­ç»ƒå‚æ•°ï¼Œå»ºè®®æ–°å»ºè¾“å‡ºç›®å½•é‡æ–°è®­ç»ƒ

---

## ä¸‹æ¸¸ä»»åŠ¡

### 1. æå–é¢„è®­ç»ƒç‰¹å¾

```python
import torch
from dinov2.models import build_model_from_cfg
from omegaconf import OmegaConf

# åŠ è½½é…ç½®
cfg = OmegaConf.load("configs/train/prostate_vitb14_mm-dino.yaml")

# æ„å»ºæ¨¡å‹
model = build_model_from_cfg(cfg, only_teacher=True)

# åŠ è½½é¢„è®­ç»ƒæƒé‡
checkpoint = torch.load("output/eval/best/teacher_checkpoint.pth")
model.load_state_dict(checkpoint["teacher"])
model.eval()

# æ¨ç†
with torch.no_grad():
    # è¾“å…¥ï¼š(batch, channels, height, width)
    # å¯¹äº 3 ä¸ªåºåˆ—ï¼šchannels=3
    # å¯¹äº 3 ä¸ªåºåˆ— + maskï¼šchannels=4
    features = model(input_tensor)  # (batch, num_patches, embed_dim)
```

### 2. åˆ†å‰²ä»»åŠ¡å¾®è°ƒ

```python
# ä½¿ç”¨é¢„è®­ç»ƒ backbone åˆå§‹åŒ–åˆ†å‰²æ¨¡å‹
from dinov2.models import build_model_from_cfg

# 1. åŠ è½½é¢„è®­ç»ƒ backbone
backbone = build_model_from_cfg(cfg, only_teacher=True)
checkpoint = torch.load("pretrained_weights.pth")
backbone.load_state_dict(checkpoint["teacher"])

# 2. æ„å»ºåˆ†å‰²æ¨¡å‹ï¼ˆä¾‹å¦‚ UNetï¼‰
class SegmentationModel(nn.Module):
    def __init__(self, backbone, num_classes=2):
        super().__init__()
        self.backbone = backbone
        self.decoder = UNetDecoder(embed_dim=768, num_classes=num_classes)
    
    def forward(self, x):
        features = self.backbone(x)
        mask = self.decoder(features)
        return mask

# 3. å¾®è°ƒ
model = SegmentationModel(backbone, num_classes=2)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
# ... è®­ç»ƒå¾ªç¯
```

### 3. åˆ†ç±»ä»»åŠ¡å¾®è°ƒ

```python
# ä½¿ç”¨é¢„è®­ç»ƒç‰¹å¾è¿›è¡Œå‰åˆ—è…ºç™Œåˆ†çº§
from dinov2.eval.log_regression import eval_log_regression_with_model

# çº¿æ€§æ¢æµ‹ï¼ˆLinear Probingï¼‰
val_results = eval_log_regression_with_model(
    model=model,  # é¢„è®­ç»ƒæ¨¡å‹
    train_dataset_str="ProstateSupervised:split=TRAIN:root=/data",
    val_dataset_str="ProstateSupervised:split=VAL:root=/data",
    metric_types=["accuracy", "f1", "auc"],
    num_workers=4,
)

print("Validation Accuracy:", val_results["accuracy"])
```

### 4. Few-Shot å­¦ä¹ 

é¢„è®­ç»ƒæ¨¡å‹åœ¨å°‘æ ·æœ¬åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ï¼š

```python
# ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®å¾®è°ƒ
train_dataset = make_dataset(
    dataset_str="ProstateSupervised:split=TRAIN:root=/data",
    # ä»…ä½¿ç”¨ 10% çš„æ ‡æ³¨æ•°æ®
    percentage_labels=0.1,
)

# å†»ç»“ backboneï¼Œä»…è®­ç»ƒåˆ†ç±»å¤´
for param in backbone.parameters():
    param.requires_grad = False

classifier = nn.Linear(backbone.embed_dim, num_classes)
optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)
```

---

## å¸¸è§é—®é¢˜ FAQ

### Q1: æ‰¾ä¸åˆ°æ•°æ®é›† / è·¯å¾„ä¸å¯¹

**é—®é¢˜ï¼š**
```
FileNotFoundError: [Errno 2] No such file or directory: '/path/to/data/patient_001'
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ `dataset_path` ä¸­çš„ `root` æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„
2. ç¡®è®¤ CSV æ–‡ä»¶ä¸­çš„ç—…ä¾‹ ID ä¸æ•°æ®ç›®å½•åç§°å®Œå…¨ä¸€è‡´
3. è¿è¡Œæ•°æ®è´¨é‡æ£€æŸ¥è„šæœ¬ï¼ˆè§"æ•°æ®å‡†å¤‡"éƒ¨åˆ†ï¼‰

```bash
# ç¡®è®¤è·¯å¾„
ls /path/to/prostate_dataset/patient_001/
```

### Q2: CUDA / æ˜¾å­˜ä¸å¤Ÿ

**é—®é¢˜ï¼š**
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. **å‡å° batch size**ï¼š
   ```yaml
   train:
     batch_size_per_gpu: 4  # ä» 8 å‡åˆ° 4
   ```

2. **å‡å°æ¨¡å‹å°ºå¯¸**ï¼š
   ```yaml
   student:
     arch: glioma_vit_small  # ä» base æ”¹ä¸º small
   ```

3. **å‡å°å›¾åƒå°ºå¯¸**ï¼š
   ```yaml
   crops:
     global_crops_size: 192  # ä» 224 å‡åˆ° 192
   ```

4. **å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰ï¼š
   ```python
   # åœ¨æ¨¡å‹å®šä¹‰ä¸­
   torch.utils.checkpoint.checkpoint_sequential(...)
   ```

### Q3: å­¦ä¹ ç‡è®¾ç½®ä¸å½“å¯¼è‡´ loss ä¸º NaN

**é—®é¢˜ï¼š**
```
AssertionError: NaN detected in loss
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. **é™ä½å­¦ä¹ ç‡**ï¼š
   ```yaml
   optim:
     base_lr: 1e-4  # ä» 3.5e-4 é™ä½
   ```

2. **å¢åŠ  warmup**ï¼š
   ```yaml
   optim:
     warmup_epochs: 50  # ä» 30 å¢åŠ åˆ° 50
   ```

3. **æ£€æŸ¥æ•°æ®**ï¼šç¡®è®¤ NIfTI æ–‡ä»¶æ²¡æœ‰å¼‚å¸¸å€¼
   ```python
   import nibabel as nib
   img = nib.load("patient_001/ax_t2wi.nii.gz").get_fdata()
   print(f"Min: {img.min()}, Max: {img.max()}, Mean: {img.mean()}")
   ```

4. **å¯ç”¨æ¢¯åº¦è£å‰ª**ï¼ˆå·²é»˜è®¤å¯ç”¨ï¼‰ï¼š
   ```yaml
   optim:
     clip_grad: 3.0
   ```

### Q4: mask/ROI å¤ªå°å¯¼è‡´å¢å¼ºç®—å­æŠ¥é”™

**é—®é¢˜ï¼š**
```
RuntimeError: size mismatch in RandomResizedCrop
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. **ç¦ç”¨åŸºäº ROI çš„è£å‰ª**ï¼š
   ```yaml
   crops:
     crop_from_tumor_foreground: False
   ```

2. **å¢å¤§æœ€å°è‚¿ç˜¤å°ºå¯¸**ï¼ˆéœ€è¦ä¿®æ”¹ `io.py`ï¼‰ï¼š
   ```python
   LoadTumorSliced(
       keys=[...],
       min_tumor_size=100,  # ä» 1 å¢åŠ åˆ° 100
       ...
   )
   ```

3. **è¿‡æ»¤å° ROI ç—…ä¾‹**ï¼šåœ¨ CSV ä¸­ç§»é™¤ ROI è¿‡å°çš„ç—…ä¾‹

### Q5: xFormers å®‰è£…å¤±è´¥

**é—®é¢˜ï¼š**
```
ModuleNotFoundError: No module named 'xformers'
```

**è§£å†³æ–¹æ¡ˆï¼š**

**æ–¹æ³• 1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡è·³è¿‡**
```bash
export XFORMERS_DISABLED=1
python -m train.train ...
```

**æ–¹æ³• 2ï¼šå®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬**
```bash
# CUDA 12.1
pip install xformers --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
pip install xformers --index-url https://download.pytorch.org/whl/cu118
```

**æ–¹æ³• 3ï¼šä»æºç ç¼–è¯‘**
```bash
pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers
```

### Q6: å¤šå¡è®­ç»ƒæ—¶é€Ÿåº¦æ²¡æœ‰æå‡

**å¯èƒ½åŸå› ï¼š**
1. **æ•°æ®åŠ è½½ç“¶é¢ˆ**ï¼šå¢åŠ  `num_workers`
   ```yaml
   train:
     num_workers: 8  # ä» 4 å¢åŠ åˆ° 8
   ```

2. **å° batch size**ï¼šå¢åŠ  `batch_size_per_gpu`
   ```yaml
   train:
     batch_size_per_gpu: 12  # å°½é‡æé«˜
   ```

3. **é€šä¿¡ç“¶é¢ˆ**ï¼šæ£€æŸ¥ç½‘ç»œï¼ˆInfiniBand > 10GbE > 1GbEï¼‰

4. **FSDP ç­–ç•¥ä¸å½“**ï¼šå°è¯• `FULL_SHARD`
   ```yaml
   compute_precision:
     student:
       backbone:
         sharding_strategy: FULL_SHARD  # ä» SHARD_GRAD_OP æ”¹ä¸º FULL_SHARD
   ```

### Q7: è®­ç»ƒæ—¶å†…å­˜æŒç»­å¢é•¿

**å¯èƒ½åŸå› ï¼š**
1. **æœªé‡Šæ”¾ cache**ï¼šæ·»åŠ å®šæœŸæ¸…ç†
   ```python
   # åœ¨è®­ç»ƒå¾ªç¯ä¸­æ¯éš” 100 æ¬¡è¿­ä»£
   if iteration % 100 == 0:
       torch.cuda.empty_cache()
   ```

2. **æ•°æ®åŠ è½½å™¨æ³„æ¼**ï¼šå‡å°‘ `num_workers`
   ```yaml
   train:
     num_workers: 2  # é™ä½åˆ° 2
   ```

3. **æ—¥å¿—ç´¯ç§¯**ï¼šç¼©çŸ­æ—¥å¿—è®°å½•é¢‘ç‡

### Q8: å¦‚ä½•åˆ¤æ–­è®­ç»ƒæ˜¯å¦æ­£å¸¸

**æ­£å¸¸è®­ç»ƒçš„ç‰¹å¾ï¼š**
1. **Loss ä¸‹é™**ï¼šå‰ 10-20 ä¸ª epoch åº”è¯¥æ˜æ˜¾ä¸‹é™
   - åˆå§‹ loss: ~5-7
   - 100 epoch å: ~3-4
   - æ”¶æ•›æ—¶: ~2-3

2. **å­¦ä¹ ç‡è°ƒåº¦**ï¼š
   - Warmup é˜¶æ®µï¼šå­¦ä¹ ç‡ä» 0 é€æ¸å‡é«˜
   - ç¨³å®šé˜¶æ®µï¼šä¿æŒåœ¨ base_lr
   - Cosine è¡°å‡ï¼šé€æ¸é™ä½åˆ° min_lr

3. **æ˜¾å­˜ä½¿ç”¨ç¨³å®š**ï¼šç¬¬ 10 æ¬¡è¿­ä»£åæ˜¾å­˜åº”è¯¥ç¨³å®š

4. **è®­ç»ƒé€Ÿåº¦ç¨³å®š**ï¼šit/s åœ¨ warmup ååº”è¯¥ç¨³å®š

**å¼‚å¸¸æƒ…å†µï¼š**
- âŒ Loss å§‹ç»ˆä¸å˜æˆ–ä¸Šå‡
- âŒ Loss çªç„¶å˜ä¸º NaN
- âŒ æ˜¾å­˜æŒç»­å¢é•¿
- âŒ è®­ç»ƒé€Ÿåº¦æŒç»­ä¸‹é™

### Q9: é¢„è®­ç»ƒéœ€è¦å¤šä¹…

**è®­ç»ƒæ—¶é—´ä¼°ç®—ï¼ˆå•å¡ RTX 4090ï¼‰ï¼š**
- ViT-B/14, 300 epochs, 400 ç—…ä¾‹: ~3-4 å°æ—¶
- ViT-L/14, 300 epochs, 400 ç—…ä¾‹: ~6-8 å°æ—¶

**å¤šå¡åŠ é€Ÿæ¯”ï¼š**
- 2 å¡: ~1.8x
- 4 å¡: ~3.2x
- 8 å¡: ~5.5x

**å»ºè®®ï¼š**
- å°è§„æ¨¡å®éªŒï¼ˆ<100 ç—…ä¾‹ï¼‰ï¼š50-100 epochs
- ä¸­ç­‰è§„æ¨¡ï¼ˆ100-500 ç—…ä¾‹ï¼‰ï¼š200-300 epochs
- å¤§è§„æ¨¡ï¼ˆ>500 ç—…ä¾‹ï¼‰ï¼š300-500 epochs

### Q10: å¦‚ä½•é€‰æ‹©æœ€ä½³æ£€æŸ¥ç‚¹

**æ–¹æ³• 1ï¼šåŸºäºéªŒè¯é›†æ€§èƒ½**
- å¦‚æœé…ç½®äº†è¯„ä¼°ï¼Œè®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨ä¿ç•™æœ€ä½³æ£€æŸ¥ç‚¹
- æœ€ä½³æ£€æŸ¥ç‚¹ä¿å­˜åœ¨ `output/eval/best/teacher_checkpoint.pth`

**æ–¹æ³• 2ï¼šåŸºäºè®­ç»ƒæŸå¤±**
- æŸ¥çœ‹ `training_metrics.json`
- é€‰æ‹© loss æœ€ä½çš„ checkpoint

**æ–¹æ³• 3ï¼šåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šæµ‹è¯•**
- åŠ è½½ä¸åŒ checkpoint
- åœ¨åˆ†å‰²/åˆ†ç±»ä»»åŠ¡ä¸Šè¯„ä¼°æ€§èƒ½
- é€‰æ‹©ä¸‹æ¸¸æ€§èƒ½æœ€å¥½çš„

---

## é¡¹ç›®ç»“æ„

```
Prostate/
â”œâ”€â”€ README.md                          # é¡¹ç›®è¯´æ˜ï¼ˆå½“å‰æ–‡æ¡£ï¼‰
â”œâ”€â”€ ENGINEERING_ASSESSMENT.md          # å·¥ç¨‹è¯„ä¼°æŠ¥å‘Š
â”œâ”€â”€ requirements.txt                   # Python ä¾èµ–ï¼ˆéœ€åˆ›å»ºï¼‰
â””â”€â”€ dinov2/                            # ä¸»ä»£ç ç›®å½•
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ configs/                       # é…ç½®æ–‡ä»¶
    â”‚   â”œâ”€â”€ ssl_default_config.yaml   # é»˜è®¤é…ç½®
    â”‚   â””â”€â”€ train/                     # è®­ç»ƒé…ç½®
    â”‚       â””â”€â”€ prostate_vitb14_mm-dino.yaml  # å‰åˆ—è…ºé…ç½®
    â”œâ”€â”€ data/                          # æ•°æ®åŠ è½½ä¸å¤„ç†
    â”‚   â”œâ”€â”€ datasets/
    â”‚   â”‚   â”œâ”€â”€ prostate_ssl.py       # å‰åˆ—è…º SSL æ•°æ®é›†
    â”‚   â”‚   â””â”€â”€ medical_dataset.py     # åŒ»å­¦æ•°æ®é›†åŸºç±»
    â”‚   â”œâ”€â”€ monai_transforms/          # MONAI å˜æ¢
    â”‚   â”‚   â”œâ”€â”€ io.py                  # æ•°æ®åŠ è½½
    â”‚   â”‚   â””â”€â”€ spatial.py             # ç©ºé—´å˜æ¢
    â”‚   â”œâ”€â”€ augmentations.py           # æ•°æ®å¢å¼º
    â”‚   â”œâ”€â”€ loaders.py                 # æ•°æ®åŠ è½½å™¨
    â”‚   â””â”€â”€ transforms.py              # å˜æ¢å·¥å…·
    â”œâ”€â”€ models/                        # æ¨¡å‹å®šä¹‰
    â”‚   â”œâ”€â”€ __init__.py               # æ¨¡å‹æ„å»º
    â”‚   â”œâ”€â”€ glioma_vit.py             # å¤šæ¨¡æ€ ViT
    â”‚   â””â”€â”€ vision_transformer.py      # åŸºç¡€ ViT
    â”œâ”€â”€ train/                         # è®­ç»ƒè„šæœ¬
    â”‚   â”œâ”€â”€ train.py                  # ä¸»è®­ç»ƒè„šæœ¬
    â”‚   â””â”€â”€ ssl_meta_arch.py          # SSL æ¶æ„
    â”œâ”€â”€ fsdp/                          # FSDP æ”¯æŒ
    â”‚   â””â”€â”€ __init__.py
    â”œâ”€â”€ loss/                          # æŸå¤±å‡½æ•°
    â”‚   â”œâ”€â”€ dino_clstoken_loss.py
    â”‚   â”œâ”€â”€ ibot_patch_loss.py
    â”‚   â””â”€â”€ koleo_loss.py
    â”œâ”€â”€ layers/                        # ç¥ç»ç½‘ç»œå±‚
    â”‚   â”œâ”€â”€ attention.py
    â”‚   â”œâ”€â”€ block.py
    â”‚   â””â”€â”€ patch_embed.py
    â”œâ”€â”€ utils/                         # å·¥å…·å‡½æ•°
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ utils.py
    â”‚   â””â”€â”€ dtype.py
    â”œâ”€â”€ tests/                         # æµ‹è¯•
    â”‚   â””â”€â”€ test_prostate_ssl_training.py
    â””â”€â”€ visualization/                 # å¯è§†åŒ–
        â””â”€â”€ train/
            â””â”€â”€ vis_loss.py
```

---

## å¼•ç”¨

å¦‚æœä½ ä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@article{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@article{chen2023towards,
  title={Towards a general-purpose foundation model for computational pathology},
  author={Chen, Richard J and Ding, Tong and Lu, Ming Y and Williamson, Drew FK and Jaume, Guillaume and Song, Andrew H and Chen, Bowen and Zhang, Andrew and Shao, Daniel and Shaban, Muhammad and others},
  journal={Nature Medicine},
  year={2024}
}
```

---

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº Meta Platforms, Inc. çš„ DINOv2 é¡¹ç›®å¼€å‘ï¼Œéµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤ GitHub Issue
- é‚®ä»¶ï¼š[ä½ çš„é‚®ç®±]

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€**
